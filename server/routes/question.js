router.post('/', async (req, res) => {
  const totalStart = Date.now();

  const { context, question } = req.body;

  console.log('\nğŸŸ¡ [QUESTION START]');
  console.log('ğŸ“ ì§ˆë¬¸:', question);
  console.log('ğŸ“š context ê¸¸ì´:', context?.length);
  console.log('ğŸ“˜ context ë¯¸ë¦¬ë³´ê¸°:', context?.slice(0, 150));

  if (!context || !question) {
    console.warn('âš ï¸ ì§ˆë¬¸ ë˜ëŠ” context ëˆ„ë½');
    return res.status(400).json({ message: 'ì§ˆë¬¸ê³¼ ë¬¸ë§¥(context)ì´ í•„ìš”í•©ë‹ˆë‹¤.' });
  }

  const prompt = `
ì•„ë˜ ë¬¸ë§¥ì€ ì–´ë–¤ ì£¼ì œì— ëŒ€í•œ ì„¤ëª…ì´ì•¼.
ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë¶€ë“œëŸ½ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜. ğŸ§’

- ë°˜ë“œì‹œ ë¬¸ë§¥ ì•ˆì— ìˆëŠ” ì •ë³´ë§Œ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
- ì–´ë ¤ìš´ ìš©ì–´ëŠ” ê´„í˜¸ë¡œ í’€ì–´ì¤˜.
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ë„£ê³ , ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³  ì‰½ê²Œ ë§í•´ì¤˜.
- ë¬¸ì¥ì€ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹¨ë½ì„ ë‚˜ëˆ ì¤˜.

ğŸ“˜ ë¬¸ë§¥:
${context}

â“ ì§ˆë¬¸:
${question}
  `;

  try {
    console.time('ğŸ§  GPT ì‘ë‹µ ì‹œê°„');

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'ë„ˆëŠ” ì–´ë¦°ì´ì˜ ê¶ê¸ˆì¦ì„ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ì„ ìƒë‹˜ì´ì•¼.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.5
    });

    console.timeEnd('ğŸ§  GPT ì‘ë‹µ ì‹œê°„');

    const answer = completion.choices[0].message.content.trim();
    console.log('âœ… GPT ì‘ë‹µ ì™„ë£Œ');

    const totalDuration = Date.now() - totalStart;
    console.log(`âœ… ì§ˆë¬¸ ì‘ë‹µ ì™„ë£Œ â†’ ì´ ì†Œìš” ì‹œê°„: ${totalDuration}ms`);

    res.json({ answer });
  } catch (error) {
    console.error('âŒ ì§ˆë¬¸ ì‘ë‹µ ì‹¤íŒ¨:', error.message);
    res.status(500).json({ message: 'ì§ˆë¬¸ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.', error: error.message });
  }
});
